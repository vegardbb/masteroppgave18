\section{KVolve - hvordan endre NoSQL - datamodeller uten nedetid}

Den første artikkelen som presenteres i dette kapitlet handler om levende oppdatering av datamodellen til høytilgjengelige webapplikasjoner uten tjenesteavbrudd eller ytelsesdemping, der et nøkkel-verdi-datalager (her representert ved Redis) brukes til å persistere applikasjonens data. Selv om nøkkel-verdi-datalagre er skjemaløse, påfører webapplikasjonen datamodellen gjerne en logisk aggregatstruktur realisert med spesielle dataformat, som protokollbufre, Avro - objekt eller JSON - dittoer \citep{saur2016}.

\subsection{Bakgrunn}
Nye funksjonelle krav som spesifiseres for webapplikasjoner medfører ofte endringer i datamodellen.  Typiske endringer i aggregatet inkluderer fjerning av, gi nytt navn til eller tillegging av ett eller flere attributter. Dataformatet til aggregatet kan også bli endret fra for eksempel JSON til Apache Thrift. Sistnevnte innehar for øvrig støtte for versjonering og sporing av ''dataformatet''.

Den typiske metoden å implementere slike oppdateringer i NoSQL - datamodellen er å migrere dataene fra den gamle datamodellen, slå av samtlige noder i tjenesten, installere oppdateringen, konvertere dataene til å passe den nye modellen, og deretter importere dataene inn i den oppdaterte databasen. Dette medfører selvsagt nedetid i systemet, som tradisjonelt sett kan bortdefineres (jamfør kapittel 2.1), da vedlikeholdsarbeid gjøres på et tidspunkt ingen behøver systemets tjenester.

I en høytilgjengelig webapplikasjon som betjener forespørsler nærmest døgnet rundt er denne stopp-og-restart-strategien uholdbar. At konvertering av data til å konformere til et nytt aggregatformat tar tid er også problematisk. Ved å opprettholde bakoverkompabilitet på dataformatet kan systemets utviklere trygt oppgradere datamodellen med en manuell, rullerende teknikk, men da vil man samtidig legge kraftige begrenser på hvordan applikasjonen videreutvikles.

\subsection{Løsning}
KVolve, hvis navn kommer fra frasen \emph{Key-value store evolution}, er en utvidelse av det populære databasesystemet Redis. Det er implementert i C i form av et modulært bibliotek kompilert sammen med Redis. Kildekoden til dette selvstendige databasesystemet ble publisert på GitHub den 18. september 2016 \footnote{Tilgjengelig på Github, \url{https://github.com/plum-umd/kvolve}}, og benytter kildekodeversjon redis-2.8.17 av Redis i sin implementasjon. KVolve fungerer som et eget databasesystem som tilbyr støtte for levende skjemaoppgradering gjennom lat datamigrering (eng. ''lazy migration'') \citep{saur2016}.

Systemet eksponerer aggregatformatets versjon for applikasjonen. Data konverteres ikke på ivrig vis ved for eksempel å iterere over nøklene i databasen og endre både dem (hvis nødvendig) og deres verdier. Formatkonvertering av nøkler og verdier utføres når applikasjonen gjør oppslag på dem. KVolve sporer versjonene til de forskjellige dataobjektene ved hjelp av prefikser i nøklene. For hvert dataobjekt lagres en ''version tag'' som i tilfeller der dataobjekt ikke har blitt migrert kan være eldre enn dets logiske versjon \citep{saur2016}.

Idet applikasjonen kopler til KVolve må den indikere hvilken logisk versjon av datamodellen den forventer å få. Tilkoplingen tillates hvis den oppgitte versjonen tilsvarer den nyeste KVolve har opprettet. Ved oppgradering av datamodellen må logisk nok også selve applikasjonen oppgraderes for å kunne behandle den nye versjonen. Dette kan for eksempel gjøres på manuelt, rullerende vis. For å kunne ta i bruke dette systemet kreves det ingen manuell versjonshandtering i applikasjonen da datamodellen som applikasjonen KVolve lagrer data til til enhver kan se en logisk konsistent versjon av datamodellen \citep{saur2016}.

% TODO: Beskriv state transformation function i dsu-kapitlet
Med dette systemet kan utviklere definere en oppgraderingsspesifikasjon som består av en mengde transformasjonsfunksjoner, som likner på det \cite{hicks2005dsu} kaller for ''state transformation functions'', i forbindelse med dynamisk oppdatering. Michael Hicks er for øvrig en av medforfatterne av denne artikkelen. Oppgraderingsspesifikasjonen definerer hvordan eksisterende data må transformeres for å passe den nye datamodellen. Disse transformasjonsfunksjonene kompileres til en delt objekt - fil som KVolve kan lese inn ved hjelp av I/O - grensesnittet til Redis. Når datamodellen er oppdatert, blir dette delte objektet persistert til disk i Redis.

Selve datatransformasjonen følger en lat strategi, altså blir data transformert i tråd med spesifikasjonen først når den spørres etter i applikasjonen. Lat datamigrering er også en kjent strategi som kan benyttes ved rullerende oppgraderinger av datamodeller, der dataobjekter som aksesseres konverteres til det nye aggregatformatet når spørringer inntreffer. Denne konverteringen gjøres da for hver enkelt spørring, og legger en vesentlig demper på spørreytelsen tilø databasen. Late beregningsstrategier står sentralt i det funksjonelle programmeringsparadigmet, der de utgjør en vesentlig faktor for ytelsen til språk som Haskell, Scala og Erlang.

KVolve definerer to typer oppdateringer av formater i datamodellen: 1: Oppdatering kun av \\ nøkkelformatet og 2: oppdatering av nøkkelformatet og verdiformatet. Ved sistnevnte påkalles transformasjonsfunksjonen med referanse til en gammel nøkkel i form av en streng og en referanse til en mengde binærdata, hvilket representerer verdien strengnøkkelen peker på i databasen, som argumenter. Transformasjonsfunksjonen bruker disse referansene til å endre nøkkelen og dets assosierte verdi til å samsvare med den nye versjonen av datamodellen. Figur 1 til og med 5 illustrerer et eksempel på en datamodelloppgradering \citep{saur2016}.

\subsection{Evaluering av løsning}
Artikkelens eksperimentelle resultater kan kort oppsummeres som følger: Ved hjelp av ytelsesmålingsverktøy inebygd i Redis ble det avdekket lite ekstra kostnad i ytelse ved normale databaseoperasjoner, og versjonslagring og dataoppdatering medfører et tillegg i lagringsforbruk på inntil 15~\% (128.6 MB kontra 112.1 MB). I tillegg ble en test utført der filsystemet brukt til å lagre data med, RedisFS, ble oppdatert. I denne oppdateringen utføres også navneendring på enkelte nøkler og komprimering av dataverdier. Den late datatransformasjonsstrategien utklasser stopp-og-restart-strategien i tidsbruk. Offline datamigrasjon brukte 12 sekunder på nevnte oppdatering. Versjonskontrolleringen i KVolve medfører naturlig nok også litt ekstra minnebruk. Evalueringene ble utført på én enkel datamaskin med 24 prosessorkjerner og 32 GB RAM, med operativsystem Red Hat Enterprise Linux, versjon 6.5.

\emph{Redis-bench} er et innebygd benchmarking - verktøy i Redis. Redis-bench emulerer en klientprosess som sender forespørsler til Redis-databasetjeneren. For denne ytelsestestingen av KVolve er antallet nøkler i databasen konfigurert til én million, og antallet operasjoner til fem millioner, slik at testen strekker over lang tid og mange forespørsler. Dermed får man et klarere bilde av det langsiktige ressursoverheadet det dynamiske skjemaoppgraderingsrammeverket påfører applikasjonen, og i tillegg blir testscenariet så realistisk som mulig.

For å få stabile testresultater som eliminerer eksepsjonelle enkeltresultater har benchmarkingen blitt kjørt flere ganger og tallene \cite{saur2016} lister opp i tabell 1 av artikkelen er mediantider målt med en nøyaktighet på hundredels sekundet, beregnet utifra i alt 11 forsøk.

Ytelsespåvirkningen (målt i antall spørringer per sekund) til to forskjellige applikasjonsoppgraderinger har blitt testet. I det ene scenariet har RedisFS, et filsystem hvis metadata som inoder og kataloger og filsystemdata er lagret i Redis, blitt oppgradert fra versjon \texttt{redisfs.5} til \texttt{redisfs.7}. Tre forskjellige metoder har blitt brukt i oppgraderingene. I den ivrige metoden blir forespørselstrafikken til Redis avbrutt helt, navngivning av nøkler utføres ved behov og data migrereres på manuelt vis. KVolve sin oppgraderingsmetode, der tjenesteforespørsler blir behandlet mens oppgraderingen utføres, er blitt realisert med kodeendringsverktøyet Kitsune, som også er blitt utviklet ved universitet ved Maryland av blant annet artikkelens hovedforfatter. Den tredje metoden er den manuelle, late migrasjonsmetoden beskrevet i kapittel 12 av \cite{sadalage2013}.

I det andre oppdateringseksperimentet ble et sosialt medium implementert ved hjelp grafbiblioteket Amico (det italienske ordet for ''venn''). I dette systemet ble Amico - komponenten oppgradert fra versjon \texttt{1.2.0} til \texttt{2.0.0}, både ved manuelle datamigrering og ved hjelp av KVolve. Med datamigrasjon på vanlig, ivrig vis var applikasjonen utilgjengelig i totalt ett minutt og 27 sekunder, mot ett sekund for KVolve \citep{saur2016}. Figur 7 illustrerer disse ytelsesforskjellene tydelig og kvantitativt.

\subsection{Styrker og svakheter}
Til tross for artikkelens praktiske tilnærming er den publiserte kildekoden kun ment for å være en proof-of-concept - implementasjon av levende skjemaoppgradering. Ved evaluering av systemet har det blitt foretatt både mikro-benchmarking og marko-benchmarking, altså har man testet oppgraderingsmekanikkens ytelsespåvirking både på databasens indre ytelse og dets innvirkning på en kjørende webapplikasjon i sin helhet.

Evalueringsseksjonen fokuserer ikke på å sammenlikne KVolve med andre systemer som organiserer skjemaendringer på dynamisk vis. Dette kan ha noe med at samhandling mellom datammodellendringer og applikasjonslogikken er en oppgave som tradisjonelt overlates til den enkelte applikasjonsvedlikeholder. Derfor er det svært få systemer KVolve kan sammenliknes med. Ett sammenlignbart system \cite{saur2016} nevner er Googles F1, som har en asynkron protokoll som kan legge til å fjerne tabeller kolnner og indekser på dynamisk vis slik at F1 har tilgang til datamodellen under oppgradering. Her blir linearisering av oppdateringer handtert ved hjelp av fysiske klokker levert av TrueTime API-et til Google. F1 støtter imidlertid ikke endring av ProtoBuf - formatet som lagres i dets kolonner.

De fem første figurene i artikkelen gir et godt bilde av en eksempelapplikajson som henter inspirajson fra \cite{sadalage2013} og hvordan KVolve oppfører seg med de gitte objektformater. Figur 6 og 7 illustrerer tydelig ytelsesfordelen KVolve gir sammenliknet med konvensjonell lat datamigrasjon og ivrig, rullerende oppdatering.

Et annet poeng til denne artikkelen er hvilken type problem med levende oppgradering av databaser den prøver å løse. KVolve behandler oppgradering av datamodeller, ikke hele databaseapplikasjoner, slik som Imago kan få til. Det påpekes i sistnevntes disfavør at mens den realiserer atomisk oppgradering av applikasjoner så er det på bekostning av en vesentlig økning, om enn midlertidig, ressursbruk i form av dataduplisering og dobbelt opp av noder.

Testene referert til i forrige delkapittel er ikke gjort i et reelt distribuert system med forskjellige maskiner på forskjellige datasentre rundt om i verden, men på én enkelt datamaskin som bruker loopback-grensesnittet (localhost). Testresultatene gir altså ikke et bilde av hvordan KVolve kan yte i et moderne produksjonsmiljø, et aspekt artikkelens konklusjon gjerne har lyst til å finne ut av ved å få KVolve implementert på Redis Cluster.

