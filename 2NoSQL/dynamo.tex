\section{Amazon Dynamo}

Her rettes fokuset mot en berømt artikkel hvis primære fokus var å besvare Amazon sitt problem med skalering av skriveoperasjoner i et kommersielt netthandelsystem som betjener flere hundre tusen forbrukere verden over. Den hypotetiske systemarkitekturen artikkelen beskriver, Dynamo, er stamfar til mange populære NoSQL-databasesystemer lansert som åpen kildekode, deriblant Apache Cassandra, Basho Riak, Amazons DynamoDB og Linkedins Project Voldemort. Drivkraften bak designet av dette likemannssystemet er den samme som den bak vårt ønske om å kunne migrere data levende i det distribuerte produksjonsmiljøet: Høyere tilgjengelighet for interaksjon mellom brukernes klientapplikasjoner og deres databasetjenere. Derfor er en god forståelse av problemstillingene og utfordringene Dynamo løser, samt hvordan løsningene kan implementeres, relevant for oppgavens problemstilling.

\subsection{Bakgrunn for artikkelens arbeid}

% Introduksjon/Abstract
\cite{decandia2007} presenterer arkitekturen til Dynamo, et høytilgjengelig, distribuert nøkkel-verdi-lager som ved nettverkspartisjoner ofrer replikakonsistens til fordel for å være mottakelig for lese - og skriveforespørsler fra diverse mikrotjenester som lever i Amazons applikasjoner. I kjernen av problemet denne distribuerte databasearkitekturen forsøker å løse, ligger et sterkt krav om at enhver kunde av Amazons netthandel alltid skal kunne legge artikler i handlekurven. Handlekurven i nettbutikken, så vel som hver eneste artikkel i nettbutikken, skal til enhver tid kunne interageres med. Ethvert avbrudd i denne tjenesten kan og vil medføre monetære tap, enten direkte i form av utsatte handler, eller indirekte i form av økende mistro hos forbrukerne. Amazon.com er samlet sett en gigantisk, distribuert netthandelapplikasjon bestående av mange tusen nettverkskomponenter og uavhengige tjenere spredt utover mange datasentre. Feil oppstår kontinuerlig i enkeltkomponenter i dette systemet.

Amazon.com er en av verdens største e-kommersplattformer. Den består av flere tusen uavhengige tjenerkomponenter lokalisert i flere datasentre verden over, og betjener flere titalls millioner kunder samtidig ved julehøytider når besøkstrafikken er på sitt høyeste \citep{pepitone2010}. Et knippe av disse tjenestene er illustrert som testimonale på økosystemets diversitet i figuren ''Figure 1'' i \citep{decandia2007}. Hvis én enkelt komponent i den avanserte tjenestearkitekturen netthandelen avhenger av for å være oppegående påkrever vedlikeholdsarbeid, går det ikke an å ta ned hele nettbutikken fullstendig for så mye som én time uten å tape en uutholdelig mengde millioner dollar i urealiserte inntekter. Derfor stilles svært høye ytelses - og pålitelighetskrav til denne e-kommersplattformen. I tillegg må dette komplekse systemet kunne skaleres horisontalt inkrementelt, altså at det distribuerte systemet kan utvides med én lagringsnode av gangen med minimal påvirkning på dets tjenesteytelsesevne.

I et stort, distribuert system vil fatale tjenerfeil, det vil si feilscenarier der en enkelt tjener følgelig blir utilgjengelig for dets brukere, inntreffe jevnlig, og med høy frekvens. Bevis: Hvis variabelen \(N\) denoterer et stort antall tjenere i et distribuert system, og sannsynligheten for at én tjener lider en fatal tjenerfeil i løpet av ett døgn estimeres til \(p\), så er sannsynligheten for at minst én tjener i klyngen blir utilgjengelig gitt ved \(1-(1-p)^s\). Et konkret eksempel: \(p=0.05, s=50 => 1-(1-p)^s=0.9231\). I en mellomstor klynge med 50 tjenere, der hver tjener feiler med en sannsynlighet på fem prosent i løpet av et døgn, så er sannsynligheten for at samtlige tjenere er oppegående i løpet av et helt døgn under åtte prosent. For at så lite datavolum skal være utilgjengelig til enhver tid i et distribuert databasesystem, må det fordele datalasten jevnt utover alle tjenerne, i tillegg til å bestå av mange tjenere.

Helt siden deres framvekst på 80 - tallet har applikasjonsdata i større produksjonsmiljø blitt lagret av relasjonelle databasystemer. \cite{decandia2007} anser imdlertid transaksjonsbasert lagring som en suboptimal og ineffektiv løsning for sitt eget produksjonsmiljø, av hovedsaklig to årsaker:

\begin{description}
  \item [Horisontal skalerbarhet] Som vist i det tidligere nevnte hypotetiske systemet Hush \citep{george2011} er tradisjonelle relasjonsdatabaser lite fleksible når det kommer til datareplikering i distribuerte databaser. \cite{decandia2007} bemerker også at det er vanskelig å skalere ut og partisjonere data jevnt utover lagringsnodene i distribuerte, relasjonelle databasesystemer, på tross av at de mest avanserte relasjonelle DBMSene støtter noen former for klyngeoperasjoner.
  \item [Unødvendige DBMS-funksjoner] Tjenestearkitekturen til Amazon har behov for en svært begrenset mengde funksjoner fra dets datalager, og sjelden behøves det at databasen skal kunne utføre avanserte oppgaver som triggere og lagrede prosedyrer, eller kjøre komplekse spørringer aggregeringsoperasjon som summering og gjennomsnitt på enkeltverdier på enkeltattributter over flere dataobjekter. Flesteparten av de enkeltstående tjenestene som eksempelvis handterer bestselgerlister, handlevogner, kundepreferanser, salgsstatistikk, og innloggingsdata, både spør etter og persisterer dataobjekter utelukkende på enkeltnøkler. Altså er de korresponderende abstrakte relasjonsmodellene for hver av disse uavhengige tjenestene assossiasjonsløse, det vil si at de kan modelleres som én enkeltstående, kompleks entitet, med nøsting av objekter og lister.
\end{description}

Følgelig går Dynamo inn for en enkel spørringsmodell: Ethvert dataobjekt identifiseres med en unik (hash)nøkkel. Alle skrive - og leseoperasjoner i lagringssystemet gjøres gjennom oppslag på en slik ID. Samtlige spørringer gjøres på ett enkelt dataobjekt ad gangen slik at det ikke er behov for å innføre støtte assosiasjoner mellom ''tuplene'' i datamodellen.  % Skriv om spørrings-APIet til Dynamo

% bryt-opp
Dynamo sitt systemdesign ble primært laget for å kunne tekkes Amazons storskala - produksjonsmiljø med flere titalls millioner samtidig påloggede forbrukere. Det distribuerte lagringssystemet som realiserer Dynamos arkitektur er designet både for tilgjengelighet og skalerbarhet. Førstnevnte kvalitetsattributt realiseres gjennom planlegging for feilsituasjoner, og motvirkning av effektene diverse typer feil kan ha. Feil kan til eksempel oppstå i nodens maskinvare eller dens kjørende programvareprosess. Sistnevnte oppfylles ved å implementere en lastbalanseringsalgoritme som fordeler ansvaret for lagring av de enkelte dataobjektene utover nodene i lagringssystemet. Hvis én av lagringsnodene svikter og blir utilgjengelig, kan algoritmen omfordele data til de andre nodene i live.

Utviklerne bak Dynamo valgte av hensyn til tilgjengelighetskravene å gjøre replikering av dataobjekter asynkront, derav kan ikke det samme skrivekonsistensnivå som vi finner hos relasjonelle databasesystem oppfylles. Årsaken til dette tilfellet er at datalagret verken kan eller vil kontrollere hvorvidt hver enkelt spørring mottar eller opererer på dataobjektets nyeste utgave, altså tillater databasen lesing av foreldede data. Hva angår ACID - egenskapene fokuserer Dynamo på å opprettholde atomisiteten til spørreoperasjonene, på grunn av kravene \cite{decandia2007} stiller til spørringsmodellen. Altså lagrer Dynamo aggregatobjekter som innehar hele den persisterte tilstanden som applikasjonene til Amazon opererer på i primærminne. Av hensyn til skrive-tilgjengeligheten isoleres ikke spørreoperasjonene, hvilket betyr at systemet tillater at skriveoperasjoner kan bli tapt, jamfør Last Write Wins - prinsippet. Av økonomiske hensyn er det også viktig at Dynamo, det distribuerte nøkkelverdilageret, kan kjøre på en infrastruktur bestående av billige datamaskiner, hvilket betyr få prosessorkjerner og begrenset datavolum både i primærminnet (RAM) og sekundærminne (platelager).

Artikkelens vitenskaplige bidrag er en vurdering av hvordan ulike algoritmer og teknikker kan kombineres til å implementere et høytilgjengelig nøkkelverdilager. Den viser at en database som ikke garanterer et strengt konsistensnivå trygt kan brukes i et produksjonsmiljø der frekvensen av innkommende spørringer er høy. Artikkelen viser også hvordan et slikt nøkkelverdilager kan konfigureres til å oppfylle strenge ytelseskrav i høytraffikerte produksjonsmiljø \citep{decandia2007}.

\subsection{Om Dynamos arkitektur og Amazons implementasjon} \label{dynark}

Designet til et distribuert nøkkelverdi-lager som opererer i et stort produksjonsmiljø slik som Dynamo må nødvendigvis være ganske komplekst, fordi det er mange problemer som må løses av dette designet som en monolittisk databasearkitektur ikke har. For å tekkes strenge krav til tilgjengelighet, må systemet ha gode løsninger til lastbalansering av data, datareplikering, dataobjektversjonering, og feilhandtering.

Dynamos logiske ring av noder som lagrer data er et likemannsnettverk. Et likemannsnettverk er en distribuert programvarearkitektur der alle noder utfører de samme arbeidsoppgavene. I et likemannsnettverk har hver enkelt node kjennskap til et visst antall andre noder i nettverket. I litteraturen kalles disse kjente nodene for ''naboer'' (\textsl{sitat}). En node holder rede på sine naboer i en oppslagsliste kalt ''routingtabell'' (sitat). Hvis noden mottar en forespørsel etter et objekt den ikke har, slår den opp i routingtabellen for å finne en annen node å videresende forespørselen til.

I tråd med artikkelens observasjon vedrørende Amazon-applikasjonenes begrensede behov for spørrefunksjonalitet i databasen de kontakter, har Dynamo-implementasjonen beskrevet av \cite{decandia2007} definert et spinkelt spørre - API bestående av to funksjoner: \texttt{get(\emph{key})} og \texttt{put(\emph{key, context, object})}. \texttt{get} - funksjonen er for lesespørringer. Hver lesespørring er et oppslag på en nøkkel, \emph{key}, som er tilknyttet et dataobjekt på binær form. Når \texttt{get} kalles, vil databasenoden som mottok spørringen, i artikkelen referert til som \underline{koordinatoren}, først identifisere nodene som lagrer replikaene av det ønskede dataobjektet og kontakter alle nodene som holder på disse replikerte objektene. Det aggregatet med den nyeste versjonen returneres til applikasjonsklienten. Spørringen kan også returnere en liste av objekter hvis dataversjoner divergerer, i tillegg til tilhørende metadata - da må de divergerende aggregatene flettes sammen, og en ny versjon må deretter persisteres. Amazons implementasjon av Dynamo anskuer både nøkkelen og dataobjektet som en ugjennomsiktig streng av biter.

\cite{decandia2007} sin implementasjon av Dynamo bruker Last-Write-Wins-strategien som konfliktresolusjonsalgoritme, hvilket er en lettvint løsning: Ved fletting lagrer databasenoden simpelthen den oppdateringen på det vedkommende dataobjekt som har det seneste tidsstemplet eller har høyest vektor-klokkeverdi. Slik vil en skriveoperasjon gå tapt for programvaresystemet Dynamo lagrer data for. Per nøkkelverdidatamodellen sin natur er det urimelig å forvente at det distribuerte datalageret har noen form for semantisk kjennskap til dataobjektene den tar hand om, da de for databasenodene bare er tilfeldige samlinger av binære tall. Derfor kan applikasjonsutviklere implementere sine egne konfliktresolusjonsalgoritmer som påkalles hvis samtidige skriveoperasjoner gjør at versjonshistorikken til to replikaer av et aggregat divergerer. For Amazon sine hovedsaklige bruksområder for Dynamo er ikke tapte skrivinger et problem, med unntak av handlevognsapplikasjonen kundene bruker i nettbutikken. Loggdata er ikke like kritisk som handledata, så der kan LWW-fletting trygt brukes.

\texttt{put} - funksjonen brukes både til å opprette og oppdatere lagrede dataobjekter assosiert og slått opp på nøkler. Når \texttt{put} kalles, blir først nodene som er ansvarlige for dataobjektet identifisert og kontaktet på samme måte som i \texttt{get}. I tillegg til aggregatets nøkkel, \emph{key}, har \texttt{put} to andre argumenter, \emph{context} og \emph{object}. \emph{context} - variabelen representerer metadata om dataobjektet som lagres, deriblant verdiene i dets vektorklokke. Informasjonen i \emph{context} - variabelen brukes også til å sammenliknes med tilsvarende lagret metadata i databasen for å validere dataobjektet som sendes inn i som argument i \texttt{put} - kallet.

For å identifisere hvilken node i likemannsnettverket som skal ha ansvar for oppslaget på en nøkkel \emph{k}, blir den hashet med MD5-algoritmen som returnerer en 128-bit streng \emph{h} hvis verdi faller imellom to andre IDer som hver identifiserer én separat databasenode i hashringen. Den databasenoden hvis ID er nærmest, men lavere enn \emph{h} i binærtallsystemet, er den noden som får ansvar for å levere dataobjektet med nøkkel \emph{k} ved spørringer etter denne nøkkelen.

For konsistenskontroll bruker Dynamo en egen protokoll inspirert av quorumreplikering \footnote{Begrepet \emph{quorum} er latin og betyr ''beslutningsdyktig antall''} for å replikere dataobjekter. Quorum-replikering er en datareplikeringstrategi for distribuerte datalagre som er justerbar. Et quorum er en mengde noder som tilordnes ansvaret for en spørring, til vanlig av en valgt koordinator. \cite{bailis2014} viser gjennom simulasjoner med en probalistisk sannsynlighetsmodell og evaluering av loggdata innsamlet i store, kommersielle produksjonsmiljø at quorumreplikerte databasesystemer lar databaseadministratorer i prakis stille på konsistensnivået til samtidige spørringer ved å konfigure en tuppel bestående av følgende tre tall som indikerer antallet replikeringsoperasjoner for hver innkommende forespørsel:

\begin{itemize}
  \item R - quorumstørrelse for leseoperasjon
  \item W - quorumstørrelse for skriveoperasjon
  \item N - Antall replikerte dataelementer for én enkelt nøkkel
\end{itemize}

I kontekst av Dynamo er dens replikeringsalgoritme ekvivalent med et strikt quorumsystem hvis R, W og N er definert slik at begge av følgende betingselser er oppfylt:

\begin{itemize}
  \item \(W > N/2\), altså at spørringskoordinatoren avventer bekreftelser på at over halvparten av de N replikaene fullbyrdet spørringen
  \item \(R + W > N\), altså at mengden replikaer av et aggregat spørringskoordinatoren venter på før ett av disse returneres til databaseklienten overlapper med mengden bekreftelsesmeldinger fra en skrivespørring spørringskoordinatoren venter på før den returner en bekreftelsesmelding til klienten
\end{itemize}

I et strikt quromsystem oppfylles sterk replikakonsistens, enhver lesespørring på et dataobjekt får med seg dens siste oppdatering/PUT som er skrevet til disk nettopp fordi minst én node er med både i dataobjektets skrivequorum og dets lesequorum. Det må påpekes at strikte quorumsystem venter på at samtlige noder i ethvert quorum returner svar på forespørselen fra spørringskoordinatoren, det vil si at strikte quorumsystem øker nettverksforsinkelsen til hver enkelt spørring for å sikre sterk replikakonsistens, fordi koordiantoren må nødvendigvis vente på den noden i quorumet der spørringen har høyest forsinkelse i nettverket (her antas det at nettverks-I/O er langt mer tidkrevende enn I/O-operasjoner på et platelager lokalt).

Quorum-replikeringsstrategien til Dynamo avviker et ordinært quorumsystem på to fronter. For det første: Hvis Dynamo hadde brukt et strikt quorumsystem for datareplikering, ville enkelte dataobjekter ha blitt utilgjengelige for databaseklientene, hvis nettverkspartisjoner i ringen oppstår, eller hvis de enkleste feilscenarier, der bare én enkelt node rammes, inntreffer. I tillegg ville skrivespørringer være langt mindre holdbare (eng. ''durable'') på disk \citep{decandia2007}. For det andre er Dynamos quromprotokoll ''sløv'', det vil si at en spørringskoordinator oppnevner ikke en bestemt mengde noder som alle \textbf{må} fullføre spørringen for at resultat kan sendes tilbake til databaseklienten som kjørte databasespørringen. Fordelen med denne sløvheten, eller ''fleksibiliten'', er at risikoen minimaliseres for at en spørring ikke blir besvart på grunn av at én enkelt node er utilgjengelig. For en høytilgjengelig nettbutikk som Amazon.com er nettverksforsinkelse et mye større problem enn synkronisering av replikaer, derfor konfigureres quorumet gjerne slik at \(R + W < N\), for eksempel \(R = 1, W =1, N = 3\).

For øvrig kan Dynamo sine kjerneegenskaper oppramses som følger:

\begin{description}
  \item [Konsistent hashing] Lastbalanseringsalgoritmen Dynamo bruker for å partisjonere data utover ringen av databasenoder, som er formen til den strukturen til likemannsnettverket, av databasenoder. Både data og nodeidentifikatorer hashes inn i ringen. En node, det vil si en tjenerprosess i ringen, lagrer eller holder rede på dataobjekter som har blitt hashet til forgjengernoden i ringen, således realiseres lastbalansering i et likemannsnettverk bestående av mange tjenere på en ryddig måte. Den konsistente hashalgoritmen oppfyller kravet om inkrementell skalerbarhet.
  \item [Vektorklokker] Versjoneringsteknikk brukt til å holde styr på oppdateringshistorikken til et dataobjekt. Hver databasenode som oppdaterer et bestemt aggregat, skriver et stykke metadata, en vektor på formen (\texttt{nodeNo}, \texttt{seqNo}), der førstnevnte representerer den enkelte noden som skriver dataobjektet, mens den andre variabelen er et versjonsnummer (eventuelt et tidsstempel) som øker monotont for hver gang objektet skrives til disk. Ved å lese av denne vektoren kan man utlede endringshistorikken til hvert enkelt dataobjekt og se kausaliteten mellom forskjellige \underline{versjoner} av det, altså hvilke skrivinger som er fundert på tidligere skrivinger. Hvis to samtidige oppdateringer medfører to divergerende versjoner, kan versjonshistorikken brukes til å identifisere ''synderne'' som utførte de uavhengige oppdateringene. Databaseklienten kan deretter finne ut hvilke dataverdier innad i de divergerende objektene som skal beholdes under fletteprosessen.
  \item [Slurvete quorum (eng. Sloppy quorum)] Lese - og skriveoperasjoner utføres på de første N ''friske'' databasenodene ifølge en preferanseliste konfigurert globalt i systemet. Noder som ikke responderer på forespørsler, dvs ''syke'' noder, hoppes over. Denne midlertidige økningen av medlemmer i quorumet kalles også for antientropi.
  \item [Antydet avlevering (eng. Hinted handoff)] - Teknikk for hurtig handtering av innkommende skrivinger adressert til en utilgjengelig node. Når den slurvete quorumalgoritmen finner at én av adressentene i skrivequorumet er (midlertidig) utilgjengelig, så blir skrivequorumet midlertidig utvidet med en ekstra ''opp-passernode''. Denne midlertidige vakten lagrer dataobjektet helt til den frafalne noden er tilbake i ringen. Når opp-passernoden mottar nyheter (via sladderprotokollen) om at noden som dataene opprinnelig tilhører lever igjen, blir disse avlevert til sitt opprinnelige tiltenkte lager fra opp-passernode. % bryt-opp
  \item [Merkle - trær] Et Merkle-tre er et hashtre der hver enkelt løvnode holder på en hashet verdi. Foreldrenodens tilstandsverdi tilsvarer den kumulative hashverdien av dens barn. Rekursivt sett vil dette si at rotnoden holder på den sammenlagte verdien for alle løvnodene i treet. Hvert enkelt nivå i treet er følgelig sammenliknbart med korresponderende nivå i liknende tre.
  \item [Antientropi] Mens slurvete quroumoperasjoner og antydede avleveringer kan brukes til å respondere på midlertidige fravær av noder, som kan forårsakes av at et unntak kastes i selve programvareprosessen til noden, benyttes Merkle - trær til å rebalansere datalasten i likemannsnettverket etter at en databasenode legges til eller blir permanent utilgjengelig. Merkle-trær er således en viktig datastruktur for å realisere antientropi-protokollen til Dynamo. Merkle-trær brukes til å synkronisere utdaterte replikaer uten å sende én enkelt melding per oppdaterte replika av hvert eneste lagrede dataobjekt. Istedet kan hver enkelt par av noder utveksle en hash-verdi som representerer den samlede hashverdien for deres respektive nøkkelrom. Når en node legges til eller forsvinner fra ringen, må nøkkelintervallene som nodene er ansvarlige for å lagre, omfordeles for å fordele datalasten jevnt. Hvis ringen har høy ''churn'' - rate, det vil si at noder svært ofte kommer og går ut av ringen eller at fatale eksekveringsfeil oppstår abnormalt ofte hos nodene, vil nøkkelintervallene bli rekalkulert svært ofte, noe som hemmer ytelsen til systemet.
  \item [Sladder-basert medlemskapsprotokoll (eng. ''Gossip-based membership protocol'')] // ''Gosipping'', eller sladder på godt norsk, er en masterløs, skalerbar medlemskapsprotokoll der hver enkelt node jevnlig kontakter en tilfeldig valgt nabo (''peer'') og utveksler og oppdaterer egne registrerte medlemsdata om ringen. \cite{decandia2007} registrerer også at denne ''explicit node join'' - prosessen gjør at noder blir oppmerksomme både på nye noder og nylig utilgjengelige noder, som gjør en separat distribuert feildetektor overflødig. På grunn av protokollens asynkrone natur (hver enkelt medlemskapsendring i ringen medfører ikke en direkte oppdatering hos alle nodene samtidig utstedt fra en sentral medlemskoordinator) er medlemslistene svakt konsistente. Hensikten med en slik medlemsprotokoll er både å holde styr på hvilke databasenoder som fortsatt er del av Dynamo-ringen og å detektere at en node er utilgjengelig, dvs at den er utsatt for feil, slik at systemet kan midlertidig persistere replikaer offeret for feilen hadde styr på hos noen andre noder med antydet avlevering.
  \item [Lesereparasjon (eng. ''Read repair'')] I Amazons implementasjon venter den enkelte databasenode på respons fra spørringskoordinatoren, etter å ha returnert et dataobjekt til den. Hvis spørringskoordinatoren mottok replikaer som ikke er av den nyeste versjonen, kan den sende den nyeste versjonen til de respektive noder som returnerte de utdaterte dataobjektene. Prosessen bærer navnet ''lesereparasjon'' fordi replikaer som ikke har lagret den nyeste dataversjonen, blir reparert på opportunistisk vis av spørringskoordinatoren. Denne prosessen kjøres ad-hoc og er ikke effektiv når det kommer til å synkronisere replikaer ved endringer i medlemsmassen til Dynamo-ringen. % bryt-opp
\end{description}

Denne teknologiske syntesen, tildels inspirert av distribuerte hashtabeller og quorumsystemer, medfører i sum et høytilgjengelig, feilrobust, lastbalansert nøkkelverdi-lager. De kvalitative lagringsegenskapene til lageret kan finjusteres ved å konfigurere quorumvektoren \(R, W, N\). Mange av disse teknikkene er, som vi skal se i neste delkapittel, også realisert i Project Voldemort.
